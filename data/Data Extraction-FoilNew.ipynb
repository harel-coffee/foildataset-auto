{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import scipy.sparse as ss\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106691\n"
     ]
    }
   ],
   "source": [
    "foil_train = json.load(open('foil_new/FOIL-LINGv0.5_train2017.json'))\n",
    "ourimagetrainfeats = [(int(w.strip().split()[0].split('.jpg')[0].split('COCO_train2014_')[1]), np.array(map(float, w.strip().split()[1:]))) \n",
    "                      for w in open('data/mscoco_boc_gt_train2014.txt')]\n",
    "ourimagetrainfeats = dict(ourimagetrainfeats)\n",
    "training_annotations = [l['caption'] for l in foil_train['annotations']]\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_features=None, lowercase=True)\n",
    "tf_model = tf_vectorizer.fit(training_annotations)\n",
    "training_feats = tf_model.transform(training_annotations)\n",
    "\n",
    "training_y = [0 if f['foil_word'] == 'ORIG' else 1 for f in foil_train['annotations']]\n",
    "training_image_feats = [ourimagetrainfeats[i['image_id']] for i in foil_train['annotations']]\n",
    "training_image_feats_sparse = ss.csr_matrix(np.array(training_image_feats))\n",
    "print len(training_image_feats)\n",
    "foil_test = json.load(open('foil_new/FOIL-LINGv0.5_test2017.json') )\n",
    "testing_annotations = [l['caption'] for l in foil_test['annotations']]\n",
    "ourimagetestfeats = [(int(w.strip().split()[0].split('.jpg')[0].split('COCO_val2014_')[1]),\n",
    "                     map(float, w.strip().split()[1:])) \n",
    "                    for w in open('data/mscoco_boc_gt_val2014.txt')]\n",
    "ourimagetestfeats = dict(ourimagetestfeats)\n",
    "\n",
    "testing_annotations = [l['caption'] for l in foil_test['annotations']]\n",
    "testing_feats = tf_model.transform(testing_annotations) \n",
    "testing_y = [0 if f['foil_word'] == 'ORIG' else 1 for f in foil_test['annotations']]                    \n",
    "testing_image_feats = [ourimagetestfeats[i['image_id']] for i in foil_test['annotations']]\n",
    "testing_image_feats_sparse = ss.csr_matrix(np.array(testing_image_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106691/106691 [00:08<00:00, 12026.81it/s]\n",
      "  2%|▏         | 1135/61746 [00:00<00:05, 11346.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61746/61746 [00:05<00:00, 11179.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def write_stuff(annots, ys, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for x,y in zip(annots, ys):\n",
    "            f.write('%s\\t%s\\n' % (y, x.replace('\\n', ' ').strip('\\n').strip()))\n",
    "            \n",
    "    print 'done'\n",
    "    \n",
    "    \n",
    "write_stuff(training_annotations, training_y, 'POSTraining.txt')\n",
    "write_stuff(testing_annotations, testing_y, 'POSTesting.txt')\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def dump(dirtrain, dirtest, dtypetr, dtypete):\n",
    "    for r in tqdm(range(len(dtypetr))):\n",
    "        np.save(dirtrain + '/' + str(r+1)+'.npy', dtypetr[r])\n",
    "    print 'done with training'\n",
    "    for r in tqdm(range(len(dtypete))):\n",
    "        np.save(dirtest + '/' + str(r+1)+'.npy', dtypete[r])\n",
    "    print 'done with testing'\n",
    "    \n",
    "    \n",
    "%mkdir train_img_pos test_img_pos\n",
    "dump('train_img_pos', 'test_img_pos',  training_image_feats, testing_image_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sio.mmwrite('data_new/train_feats.mtx', training_feats)\n",
    "sio.mmwrite('data_new/test_feats.mtx', testing_feats)\n",
    "sio.mmwrite('data_new/train_image_feats.mtx', training_image_feats_sparse)\n",
    "sio.mmwrite('data_new/test_image_feats.mtx', testing_image_feats_sparse)\n",
    "sio.mmwrite('data_new/train_y.mtx', ss.csr_matrix(np.array(training_y)))\n",
    "sio.mmwrite('data_new/test_y.mtx', ss.csr_matrix(np.array(testing_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'POS': u'PP',\n",
       " u'Source': u'VerbOcean',\n",
       " u'caption': u'a group of men below a table preparing food together',\n",
       " u'foil_id': 4000007,\n",
       " u'foil_word': u'below',\n",
       " u'id': 486903,\n",
       " u'image_id': 405613,\n",
       " u'target_word': u'at'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foil_train['annotations'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foiled_stuff = [a for a in foil_train['annotations'] if a['foil_word'] != 'ORIG' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'ADJ', u'ADV', u'PP', u'VERB'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = [a['POS'] for a in foiled_stuff]\n",
    "set(m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54354"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([s for s in foil_train['annotations'] if s['foil_word'] != 'ORIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
