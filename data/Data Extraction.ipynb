{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import scipy.sparse as ss\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306458 306458\n",
      "306458\n"
     ]
    }
   ],
   "source": [
    "foil_train = json.load(open('data/foilv1.0_train2017.json'))\n",
    "ourimagetrainfeats = [(int(w.strip().split()[0].split('.jpg')[0].split('COCO_train2014_')[1]), np.array(map(float, w.strip().split()[1:]))) \n",
    "                      for w in open('data/mscoco_boc_gt_train2014.txt')]\n",
    "ourimagetrainfeats = dict(ourimagetrainfeats)\n",
    "training_annotations = [l['caption'] for l in foil_train['annotations']]\n",
    "print len(training_annotations), len(foil_train['annotations'])\n",
    "tf_vectorizer = CountVectorizer(max_features=None, lowercase=True)\n",
    "tf_model = tf_vectorizer.fit(training_annotations)\n",
    "training_feats = tf_model.transform(training_annotations)\n",
    "\n",
    "training_y = [0 if f['foil_word'] == 'ORIG' else 1 for f in foil_train['annotations']]\n",
    "training_image_feats = [ourimagetrainfeats[i['image_id']] for i in foil_train['annotations']]\n",
    "training_image_feats_sparse = ss.csr_matrix(np.array(training_image_feats))\n",
    "print len(training_image_feats)\n",
    "foil_test = json.load(open('data/foilv1.0_test2017.json') )\n",
    "testing_annotations = [l['caption'] for l in foil_test['annotations']]\n",
    "ourimagetestfeats = [(int(w.strip().split()[0].split('.jpg')[0].split('COCO_val2014_')[1]),\n",
    "                     map(float, w.strip().split()[1:])) \n",
    "                    for w in open('data/mscoco_boc_gt_val2014.txt')]\n",
    "ourimagetestfeats = dict(ourimagetestfeats)\n",
    "\n",
    "testing_annotations = [l['caption'] for l in foil_test['annotations']]\n",
    "testing_feats = tf_model.transform(testing_annotations) \n",
    "testing_y = [0 if f['foil_word'] == 'ORIG' else 1 for f in foil_test['annotations']]                    \n",
    "testing_image_feats = [ourimagetestfeats[i['image_id']] for i in foil_test['annotations']]\n",
    "testing_image_feats_sparse = ss.csr_matrix(np.array(testing_image_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306458\n"
     ]
    }
   ],
   "source": [
    "# GENERATING FOR YOLO_MSCOCO\n",
    "foil_train = json.load(open('data/foilv1.0_train2017.json'))\n",
    "ourimagetrainfeats = [(int(w.strip().split()[0].split('.jpg')[0].split('COCO_train2014_')[1]), np.array(map(float, w.strip().split()[1:]))) \n",
    "                      for w in open('data/yolo_coco_thresh0.3_608x608_train.txt')]\n",
    "ourimagetrainfeats = dict(ourimagetrainfeats)\n",
    "training_annotations = [l['caption'] for l in foil_train['annotations']]\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_features=None, lowercase=True)\n",
    "tf_model = tf_vectorizer.fit(training_annotations)\n",
    "training_feats = tf_model.transform(training_annotations)\n",
    "\n",
    "training_y = [0 if f['foil_word'] == 'ORIG' else 1 for f in foil_train['annotations']]\n",
    "training_image_feats = [ourimagetrainfeats[i['image_id']] for i in foil_train['annotations']]\n",
    "training_image_feats_sparse = ss.csr_matrix(np.array(training_image_feats))\n",
    "print len(training_image_feats)\n",
    "testing_annotations = [l['caption'] for l in foil_test['annotations']]\n",
    "foil_test = json.load(open('data/foilv1.0_test2017.json') )\n",
    "testing_annotations = [l['caption'] for l in foil_test['annotations']]\n",
    "ourimagetestfeats = [(int(w.strip().split()[0].split('.jpg')[0].split('COCO_val2014_')[1]),\n",
    "                     map(float, w.strip().split()[1:])) \n",
    "                    for w in open('data/yolo_coco_thresh0.3_608x608_val.txt')]\n",
    "ourimagetestfeats = dict(ourimagetestfeats)\n",
    "\n",
    "\n",
    "testing_feats = tf_model.transform(testing_annotations) \n",
    "testing_y = [0 if f['foil_word'] == 'ORIG' else 1 for f in foil_test['annotations']]                    \n",
    "testing_image_feats = [ourimagetestfeats[i['image_id']] for i in foil_test['annotations']]\n",
    "testing_image_feats_sparse = ss.csr_matrix(np.array(testing_image_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sio.mmwrite('data/train_feats.mtx', training_feats)\n",
    "sio.mmwrite('data/test_feats.mtx', testing_feats)\n",
    "sio.mmwrite('data/train_image_feats.mtx', training_image_feats_sparse)\n",
    "sio.mmwrite('data/test_image_feats.mtx', testing_image_feats_sparse)\n",
    "sio.mmwrite('data/train_y.mtx', ss.csr_matrix(np.array(training_y)))\n",
    "sio.mmwrite('data/test_y.mtx', ss.csr_matrix(np.array(testing_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sio.mmwrite('data/train_feats.mtx', training_feats)\n",
    "sio.mmwrite('data/test_feats.mtx', testing_feats)\n",
    "sio.mmwrite('data/train_image_feats_yolococo.mtx', training_image_feats_sparse)\n",
    "sio.mmwrite('data/test_image_feats_yolococo.mtx', testing_image_feats_sparse)\n",
    "sio.mmwrite('data/train_y.mtx', ss.csr_matrix(np.array(training_y)))\n",
    "sio.mmwrite('data/test_y.mtx', ss.csr_matrix(np.array(testing_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'caption': u'A long restaurant table with rattan rounded back chairs.',\n",
       " u'foil_id': 2000001,\n",
       " u'foil_word': u'ORIG',\n",
       " u'id': 789366,\n",
       " u'image_id': 57870,\n",
       " u'target_word': u'ORIG'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foil_train['annotations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ourimagetestfeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153229"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([s for s in foil_train['annotations'] if s['foil_word'] != 'ORIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153229, 75278)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(training_y), sum(testing_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306458, 306458)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(foil_train['annotations']), len(training_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'info', u'images', u'licenses', u'annotations']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foil_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69293"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(foil_train['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346465"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "69293 * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
