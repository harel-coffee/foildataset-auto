{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import scipy.sparse as ss\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import random\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60262 53381 73057 77002\n",
      "60262 7925\n"
     ]
    }
   ],
   "source": [
    "foil_train = json.load(open('foil_new/FOIL-LINGv0.5_train2017.json'))\n",
    "\n",
    "\n",
    "\n",
    "foil_train_VERB = [s for s in foil_train['annotations'] if s['POS'] == 'VERB'] + [s for s in foil_train['annotations'] if s['foil_word'] == 'ORIG']\n",
    "foil_train_ADJ = [s for s in foil_train['annotations'] if s['POS'] == 'ADJ'] + [s for s in foil_train['annotations'] if s['foil_word'] == 'ORIG']\n",
    "foil_train_ADV = [s for s in foil_train['annotations'] if s['POS'] == 'ADV'] + [s for s in foil_train['annotations'] if s['foil_word'] == 'ORIG']\n",
    "foil_train_PP = [s for s in foil_train['annotations'] if s['POS'] == 'PP'] + [s for s in foil_train['annotations'] if s['foil_word'] == 'ORIG']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "random.shuffle(foil_train_VERB)\n",
    "random.shuffle(foil_train_ADJ)\n",
    "random.shuffle(foil_train_ADV)\n",
    "random.shuffle(foil_train_PP)\n",
    "\n",
    "ourimagetrainfeats = [(int(w.strip().split()[0].split('.jpg')[0].split('COCO_train2014_')[1]), np.array(map(float, w.strip().split()[1:]))) \n",
    "                      for w in open('data/mscoco_boc_gt_train2014.txt')]\n",
    "ourimagetrainfeats = dict(ourimagetrainfeats)\n",
    "\n",
    "training_annotations_VERB = [l['caption'] for l in foil_train_VERB] \n",
    "training_annotations_ADV = [l['caption'] for l in foil_train_ADV]\n",
    "training_annotations_PP = [l['caption'] for l in foil_train_PP]\n",
    "training_annotations_ADJ = [l['caption'] for l in foil_train_ADJ]\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_features=None, lowercase=True)\n",
    "tf_model_VERB = tf_vectorizer.fit(training_annotations_VERB)\n",
    "tf_model_ADV = tf_vectorizer.fit(training_annotations_ADV)\n",
    "tf_model_PP = tf_vectorizer.fit(training_annotations_PP)\n",
    "tf_model_ADJ = tf_vectorizer.fit(training_annotations_ADJ)\n",
    "\n",
    "training_feats_VERB = tf_model_VERB.transform(training_annotations_VERB)\n",
    "training_feats_ADV = tf_model_ADV.transform(training_annotations_ADV)\n",
    "training_feats_PP = tf_model_PP.transform(training_annotations_PP)\n",
    "training_feats_ADJ = tf_model_ADJ.transform(training_annotations_ADJ)\n",
    "\n",
    "training_y_VERB = [0 if f['foil_word'] == 'ORIG' else 1 for f in foil_train_VERB]\n",
    "training_y_ADJ = [0 if f['foil_word'] == 'ORIG' else 1 for f in foil_train_ADJ]\n",
    "training_y_PP = [0 if f['foil_word'] == 'ORIG' else 1 for f in foil_train_PP]\n",
    "training_y_ADV = [0 if f['foil_word'] == 'ORIG' else 1 for f in foil_train_ADV]\n",
    "\n",
    "\n",
    "training_image_feats_VERB = [ourimagetrainfeats[i['image_id']] for i in foil_train_VERB]\n",
    "training_image_feats_sparse_VERB = ss.csr_matrix(np.array(training_image_feats_VERB))\n",
    "training_image_feats_ADJ = [ourimagetrainfeats[i['image_id']] for i in foil_train_ADJ]\n",
    "training_image_feats_sparse_ADJ = ss.csr_matrix(np.array(training_image_feats_ADJ))\n",
    "training_image_feats_ADV = [ourimagetrainfeats[i['image_id']] for i in foil_train_ADV]\n",
    "training_image_feats_sparse_ADV = ss.csr_matrix(np.array(training_image_feats_ADV))\n",
    "training_image_feats_PP = [ourimagetrainfeats[i['image_id']] for i in foil_train_PP]\n",
    "training_image_feats_sparse_PP = ss.csr_matrix(np.array(training_image_feats_PP))\n",
    "\n",
    "\n",
    "\n",
    "print len(training_image_feats_VERB), len(training_annotations_ADV), len(training_annotations_ADJ), \\\n",
    "         len(training_annotations_PP)\n",
    "\n",
    "\n",
    "\n",
    "foil_test = json.load(open('foil_new/FOIL-LINGv0.5_test2017.json') )\n",
    "\n",
    "foil_test_VERB = [s for s in foil_test['annotations'] if s['POS'] == 'VERB'] + [s for s in foil_test['annotations'] if s['foil_word'] == 'ORIG']\n",
    "foil_test_PP = [s for s in foil_test['annotations'] if s['POS'] == 'PP'] + [s for s in foil_test['annotations'] if s['foil_word'] == 'ORIG']\n",
    "foil_test_ADJ = [s for s in foil_test['annotations'] if s['POS'] == 'ADJ'] + [s for s in foil_test['annotations'] if s['foil_word'] == 'ORIG']\n",
    "foil_test_ADV = [s for s in foil_test['annotations'] if s['POS'] == 'ADV'] + [s for s in foil_test['annotations'] if s['foil_word'] == 'ORIG']\n",
    "\n",
    "random.shuffle(foil_test_VERB)\n",
    "random.shuffle(foil_test_ADJ)\n",
    "random.shuffle(foil_test_ADV)\n",
    "random.shuffle(foil_test_PP)\n",
    "\n",
    "\n",
    "testing_annotations_VERB = [l['caption'] for l in foil_test_VERB]\n",
    "testing_annotations_ADV = [l['caption'] for l in foil_test_ADV]\n",
    "testing_annotations_ADJ = [l['caption'] for l in foil_test_ADJ]\n",
    "testing_annotations_PP = [l['caption'] for l in foil_test_PP]\n",
    "\n",
    "ourimagetestfeats = [(int(w.strip().split()[0].split('.jpg')[0].split('COCO_val2014_')[1]),\n",
    "                     map(float, w.strip().split()[1:])) \n",
    "                    for w in open('data/mscoco_boc_gt_val2014.txt')]\n",
    "ourimagetestfeats = dict(ourimagetestfeats)\n",
    "\n",
    "\n",
    "\n",
    "testing_feats_VERB = tf_model_VERB.transform(testing_annotations_VERB)\n",
    "testing_feats_PP = tf_model_PP.transform(testing_annotations_PP)\n",
    "testing_feats_ADJ = tf_model_ADJ.transform(testing_annotations_ADJ)\n",
    "testing_feats_ADV = tf_model_ADV.transform(testing_annotations_ADV)\n",
    "\n",
    "\n",
    "\n",
    "testing_y_VERB = [0 if f['foil_word'] == 'ORIG' else 1 for f in foil_test_VERB]\n",
    "testing_y_ADJ = [0 if f['foil_word'] == 'ORIG' else 1 for f in foil_test_ADJ]\n",
    "testing_y_ADV = [0 if f['foil_word'] == 'ORIG' else 1 for f in foil_test_ADV]\n",
    "testing_y_PP = [0 if f['foil_word'] == 'ORIG' else 1 for f in foil_test_PP]\n",
    "\n",
    "testing_image_feats_VERB = [ourimagetestfeats[i['image_id']] for i in foil_test_VERB]\n",
    "testing_image_feats_sparse_VERB = ss.csr_matrix(np.array(testing_image_feats_VERB))\n",
    "testing_image_feats_ADJ = [ourimagetestfeats[i['image_id']] for i in foil_test_ADJ]\n",
    "testing_image_feats_sparse_ADJ = ss.csr_matrix(np.array(testing_image_feats_ADJ))\n",
    "testing_image_feats_ADV = [ourimagetestfeats[i['image_id']] for i in foil_test_ADV]\n",
    "testing_image_feats_sparse_ADV = ss.csr_matrix(np.array(testing_image_feats_ADV))\n",
    "testing_image_feats_PP = [ourimagetestfeats[i['image_id']] for i in foil_test_PP]\n",
    "testing_image_feats_sparse_PP = ss.csr_matrix(np.array(testing_image_feats_PP))\n",
    "\n",
    "print len(training_y_VERB),  sum(training_y_VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def dump(dirtrain, dirtest, dtypetr, dtypete):\n",
    "    for r in tqdm(range(len(dtypetr))):\n",
    "        np.save(dirtrain + '/' + str(r+1)+'.npy', dtypetr[r])\n",
    "    print 'done with training'\n",
    "    for r in tqdm(range(len(dtypete))):\n",
    "        np.save(dirtest + '/' + str(r+1)+'.npy', dtypete[r])\n",
    "    print 'done with testing'\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60262/60262 [00:05<00:00, 11472.20it/s]\n",
      "  3%|▎         | 1151/33616 [00:00<00:02, 11504.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33616/33616 [00:02<00:00, 11416.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 73057/73057 [00:06<00:00, 11810.28it/s]\n",
      "  3%|▎         | 1154/42163 [00:00<00:03, 11535.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42163/42163 [00:03<00:00, 11298.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 53381/53381 [00:04<00:00, 11918.78it/s]\n",
      "  4%|▍         | 1154/30738 [00:00<00:02, 11532.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30738/30738 [00:02<00:00, 11262.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 77002/77002 [00:06<00:00, 11617.04it/s]\n",
      "  2%|▏         | 1149/46018 [00:00<00:03, 11487.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46018/46018 [00:04<00:00, 10473.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%mkdir train_img_verb test_img_verb\n",
    "dump('train_img_verb', 'test_img_verb',  training_image_feats_VERB, testing_image_feats_VERB)\n",
    "\n",
    "\n",
    "%mkdir train_img_adj test_img_adj\n",
    "dump('train_img_adj', 'test_img_adj',  training_image_feats_ADJ, testing_image_feats_ADJ)\n",
    "\n",
    "%mkdir train_img_adv test_img_adv\n",
    "dump('train_img_adv', 'test_img_adv',  training_image_feats_ADV, testing_image_feats_ADV)\n",
    "\n",
    "%mkdir train_img_pp test_img_pp\n",
    "dump('train_img_pp', 'test_img_pp',  training_image_feats_PP, testing_image_feats_PP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "training_y_VERB_mod = ['REAL' if f['foil_word'] == 'ORIG' else 'FAKE' for f in foil_train_VERB]\n",
    "training_y_ADJ_mod = ['REAL' if f['foil_word'] == 'ORIG' else 'FAKE' for f in foil_train_ADJ]\n",
    "training_y_PP_mod = ['REAL' if f['foil_word'] == 'ORIG' else 'FAKE' for f in foil_train_PP]\n",
    "training_y_ADV_mod = ['REAL' if f['foil_word'] == 'ORIG' else 'FAKE' for f in foil_train_ADV]\n",
    "\n",
    "def write_stuff(annots, ys, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for x,y in zip(annots, ys):\n",
    "            f.write('%s\\t%s\\n' % (y, x.replace('\\n', ' ').strip('\\n').strip()))\n",
    "            \n",
    "    print 'done'\n",
    "    \n",
    "    \n",
    "\n",
    "testing_y_VERB_mod = ['REAL' if f['foil_word'] == 'ORIG' else 'FAKE' for f in foil_test_VERB]\n",
    "testing_y_ADJ_mod = ['REAL' if f['foil_word'] == 'ORIG' else 'FAKE' for f in foil_test_ADJ]\n",
    "testing_y_PP_mod = ['REAL' if f['foil_word'] == 'ORIG' else 'FAKE' for f in foil_test_ADV]\n",
    "testing_y_ADV_mod = ['REAL' if f['foil_word'] == 'ORIG' else 'FAKE' for f in foil_test_PP]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'A cat steeping into a gross litter box on a table!    Yikes'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_annotations_PP[13686].replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "write_stuff(training_annotations_VERB, training_y_VERB, 'VerbOnlyTraining.txt')\n",
    "write_stuff(training_annotations_ADJ, training_y_ADJ, 'AdjOnlyTraining.txt')\n",
    "write_stuff(training_annotations_ADV, training_y_ADV, 'AdvOnlyTraining.txt')\n",
    "write_stuff(training_annotations_PP, training_y_PP, 'PPOnlyTraining.txt')\n",
    "\n",
    "\n",
    "write_stuff(testing_annotations_VERB, testing_y_VERB, 'VerbOnlyTesting.txt')\n",
    "write_stuff(testing_annotations_ADJ, testing_y_ADJ, 'AdjOnlyTesting.txt')\n",
    "write_stuff(testing_annotations_ADV, testing_y_ADV, 'AdvOnlyTesting.txt')\n",
    "write_stuff(testing_annotations_PP, testing_y_PP, 'PPOnlyTesting.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sio.mmwrite('data_new/train_feats_VERB.mtx', training_feats_VERB)\n",
    "sio.mmwrite('data_new/test_feats_VERB.mtx', testing_feats_VERB)\n",
    "sio.mmwrite('data_new/train_feats_ADJ.mtx', training_feats_ADJ)\n",
    "sio.mmwrite('data_new/test_feats_ADJ.mtx', testing_feats_ADJ)\n",
    "sio.mmwrite('data_new/train_feats_ADV.mtx', training_feats_ADV)\n",
    "sio.mmwrite('data_new/test_feats_ADV.mtx', testing_feats_ADV)\n",
    "sio.mmwrite('data_new/train_feats_PP.mtx', training_feats_PP)\n",
    "sio.mmwrite('data_new/test_feats_PP.mtx', testing_feats_PP)\n",
    "\n",
    "\n",
    "sio.mmwrite('data_new/train_image_feats_VERB.mtx', training_image_feats_sparse_VERB)\n",
    "sio.mmwrite('data_new/test_image_feats_VERB.mtx', testing_image_feats_sparse_VERB)\n",
    "sio.mmwrite('data_new/train_image_feats_PP.mtx', training_image_feats_sparse_PP)\n",
    "sio.mmwrite('data_new/test_image_feats_PP.mtx', testing_image_feats_sparse_PP)\n",
    "sio.mmwrite('data_new/train_image_feats_ADJ.mtx', training_image_feats_sparse_ADJ)\n",
    "sio.mmwrite('data_new/test_image_feats_ADJ.mtx', testing_image_feats_sparse_ADJ)\n",
    "sio.mmwrite('data_new/train_image_feats_ADV.mtx', training_image_feats_sparse_ADV)\n",
    "sio.mmwrite('data_new/test_image_feats_ADV.mtx', testing_image_feats_sparse_ADV)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sio.mmwrite('data_new/train_y_VERB.mtx', ss.csr_matrix(np.array(training_y_VERB)))\n",
    "sio.mmwrite('data_new/test_y_VERB.mtx', ss.csr_matrix(np.array(testing_y_VERB)))\n",
    "sio.mmwrite('data_new/train_y_ADJ.mtx', ss.csr_matrix(np.array(training_y_ADJ)))\n",
    "sio.mmwrite('data_new/test_y_ADJ.mtx', ss.csr_matrix(np.array(testing_y_ADJ)))\n",
    "sio.mmwrite('data_new/train_y_ADV.mtx', ss.csr_matrix(np.array(training_y_ADV)))\n",
    "sio.mmwrite('data_new/test_y_ADV.mtx', ss.csr_matrix(np.array(testing_y_ADV)))\n",
    "sio.mmwrite('data_new/train_y_PP.mtx', ss.csr_matrix(np.array(training_y_PP)))\n",
    "sio.mmwrite('data_new/test_y_PP.mtx', ss.csr_matrix(np.array(testing_y_PP)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'POS': u'NA',\n",
       " u'Source': u'NA',\n",
       " u'caption': u'A young man riding a skateboard up into the air.',\n",
       " u'foil_id': 4118297,\n",
       " u'foil_word': u'ORIG',\n",
       " u'id': 732811,\n",
       " u'image_id': 491151,\n",
       " u'target_word': u'ORIG'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foiled_stuff = [a for a in foil_train['annotations'] if a['foil_word'] != 'ORIG' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'ADJ', u'ADV', u'PP', u'VERB'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = [a['POS'] for a in foiled_stuff]\n",
    "set(m) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1244)\t1\n",
      "  (0, 3149)\t1\n",
      "  (0, 3648)\t1\n",
      "  (0, 5856)\t1\n",
      "  (0, 7662)\t1\n",
      "  (0, 8138)\t1\n",
      "  (0, 8729)\t1\n"
     ]
    }
   ],
   "source": [
    "print testing_feats_VERB[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9834"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'zucchinni'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model_VERB.get_feature_names()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7925"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([s for s in foil_train['annotations'] if s['POS'] == 'VERB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20720"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([s for s in foil_train['annotations'] if s['POS'] == 'ADJ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1044"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([s for s in foil_train['annotations'] if s['POS'] == 'ADV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24665"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([s for s in foil_train['annotations'] if s['POS'] == 'PP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60262, 73057, 53381, 77002)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(foil_train_VERB), len(foil_train_ADJ), len(foil_train_ADV), len(foil_train_PP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33616, 42163, 30738, 46018)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(foil_test_VERB), len(foil_test_ADJ), len(foil_test_ADV), len(foil_test_PP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
