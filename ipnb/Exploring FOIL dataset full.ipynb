{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np \n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "import scipy.sparse as ss \n",
    "\n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC \n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training data:\n",
    "# train_feats = BOW linguistic features\n",
    "# train_image_feats = BOC image categorical features\n",
    "# train_y = FOILED or NOT FOILED => IF FOILED = 1, else 0\n",
    "train_feats = sio.mmread('data/train_feats.mtx')\n",
    "train_image_feats = sio.mmread('data/train_image_feats.mtx')\n",
    "train_target = np.array(sio.mmread('data/train_y.mtx').todense()).tolist()[0]\n",
    "#############\n",
    "# validation data: Same pattern as training; \n",
    "# The testing data comes from the karpathy 5k validation set only. \n",
    "val_feats = sio.mmread('data/test_feats.mtx')\n",
    "val_image_feats = sio.mmread('data/test_image_feats.mtx')\n",
    "val_target = np.array(sio.mmread('data/test_y.mtx').todense()).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data processing, concatinating images with\n",
    "# linguistic features and image features \n",
    "#X_train = ss.hstack([(train_feats), train_image_feats])\n",
    "#X_train = train_feats\n",
    "X_train = train_image_feats\n",
    "#X_train = ss.hstack([binarize(train_feats), train_image_feats])\n",
    "\n",
    "#X_val = ss.hstack([(val_feats), val_image_feats])\n",
    "#X_val = ss.hstack([binarize(val_feats), val_image_feats])\n",
    "#X_val = val_feats\n",
    "X_val = val_image_feats\n",
    "\n",
    "Y_train = np.array(train_target)\n",
    "Y_test = np.array(val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.751394829831\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL       0.76      0.73      0.75     75278\n",
      "       FAKE       0.74      0.78      0.76     75278\n",
      "\n",
      "avg / total       0.75      0.75      0.75    150556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with 'l1' penalty\n",
    "logistic = LogisticRegression(penalty='l2')\n",
    "logistic.fit(X_train, Y_train)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test, logistic.predict(X_val))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test, logistic.predict(X_val), \n",
    "                                    target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Accuracy =  0.75741916629\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL       0.79      0.70      0.74     75278\n",
      "       FAKE       0.73      0.82      0.77     75278\n",
      "\n",
      "avg / total       0.76      0.76      0.76    150556\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Linear Support Vector Classifier with l2 regularizer and hinge loss\n",
    "linearsvc = LinearSVC(penalty='l2', loss='hinge', verbose=1)\n",
    "linearsvc.fit(X_train, Y_train)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test, linearsvc.predict(X_val))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test, linearsvc.predict(X_val), \n",
    "                                    target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.960865060177\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL       0.96      0.96      0.96     75278\n",
      "       FAKE       0.96      0.96      0.96     75278\n",
      "\n",
      "avg / total       0.96      0.96      0.96    150556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision tree classifier\n",
    "decisiontree = DecisionTreeClassifier(random_state=0)\n",
    "decisiontree.fit(X_train, Y_train)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test, decisiontree.predict(X_val))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test, decisiontree.predict(X_val), \n",
    "                                    target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.826456600866\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL       0.76      0.96      0.85     75278\n",
      "       FAKE       0.95      0.69      0.80     75278\n",
      "\n",
      "avg / total       0.85      0.83      0.82    150556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# standard Gradient Boosting Classifier \n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, Y_train)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test, gb.predict(X_val.toarray()))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test, gb.predict(X_val.toarray()), \n",
    "                                    target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.76075347379\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL       0.76      0.77      0.76     75278\n",
      "       FAKE       0.76      0.75      0.76     75278\n",
      "\n",
      "avg / total       0.76      0.76      0.76    150556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extremely randomized tree classifier.\n",
    "ert = ExtraTreeClassifier(splitter='best')\n",
    "ert.fit(X_train, Y_train)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test, ert.predict(X_val.toarray()))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test, ert.predict(X_val), \n",
    "                                    target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(decisiontree, open('decisiontreeclassifiermodel.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.50014612503\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL     0.5001    0.5106    0.5053     75278\n",
      "       FAKE     0.5001    0.4897    0.4949     75278\n",
      "\n",
      "avg / total     0.5001    0.5001    0.5001    150556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier as in the FOIL paper\n",
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, random_state=1)\n",
    "mlp.fit(X_train, Y_train)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test, mlp.predict(X_val.toarray()))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test, mlp.predict(X_val), \n",
    "                                    target_names=target_names, digits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ..., 1 1 1] [0 0 1 ..., 1 1 1]\n",
      "[[66554  8724]\n",
      " [ 7317 67961]]\n",
      "[ 0.88410957  0.90280029]\n"
     ]
    }
   ],
   "source": [
    "cmat = metrics.confusion_matrix(Y_test, mlp.predict(X_val.todense()))\n",
    "print Y_test, mlp.predict(X_val.todense())\n",
    "print cmat \n",
    "print cmat.diagonal()/cmat.sum(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
