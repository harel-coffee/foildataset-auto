{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np \n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "import scipy.sparse as ss \n",
    "\n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC \n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training data:\n",
    "# train_feats = BOW linguistic features\n",
    "# train_image_feats = BOC image categorical features\n",
    "# train_y = FOILED or NOT FOILED => IF FOILED = 1, else 0\n",
    "train_feats = sio.mmread('data/train_feats.mtx')\n",
    "train_image_feats = sio.mmread('data/train_image_feats_yolococo.mtx')\n",
    "train_target = np.array(sio.mmread('data/train_y.mtx').todense()).tolist()[0]\n",
    "#############\n",
    "# validation data: Same pattern as training; \n",
    "# The testing data comes from the karpathy 5k validation set only. \n",
    "val_feats = sio.mmread('data/test_feats.mtx')\n",
    "val_image_feats = sio.mmread('data/test_image_feats_yolococo.mtx')\n",
    "val_target = np.array(sio.mmread('data/test_y.mtx').todense()).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data processing, concatinating images with\n",
    "# linguistic features and image features \n",
    "#X_train = ss.hstack([(train_feats), train_image_feats])\n",
    "X_train = ss.hstack([binarize(train_feats), train_image_feats])\n",
    "\n",
    "#X_val = ss.hstack([(val_feats), val_image_feats])\n",
    "X_val = ss.hstack([binarize(val_feats), val_image_feats])\n",
    "\n",
    "Y_train = np.array(train_target)\n",
    "Y_test = np.array(val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 306458/306458 [01:33<00:00, 3274.87it/s]\n",
      "100%|██████████| 150556/150556 [00:46<00:00, 3238.14it/s]\n"
     ]
    }
   ],
   "source": [
    "!rm -fr train_img_foil_yolo_real_bin\n",
    "%mkdir train_img_foil_yolo_real_bin \n",
    "path = 'train_img_foil_yolo_real_bin' \n",
    "from tqdm import tqdm\n",
    "train_img_feats = train_image_feats.tocsr().todense()\n",
    "\n",
    "for r in tqdm(range(len(train_img_feats))):\n",
    "    np.save(path + '/' + str(r+1) + '.npy', binarize(train_img_feats[r]).tolist()[0])\n",
    "    \n",
    "!rm -fr test_img_foil_yolo_real_bin\n",
    "%mkdir test_img_foil_yolo_real_bin \n",
    "path = 'test_img_foil_yolo_real_bin' \n",
    "from tqdm import tqdm\n",
    "test_img_feats = val_image_feats.tocsr().todense()\n",
    "\n",
    "for r in tqdm(range(len(test_img_feats))):\n",
    "    np.save(path + '/' + str(r+1) + '.npy', binarize(test_img_feats[r]).tolist()[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(86.62 + 88.18) / 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.751912909482\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL       0.77      0.73      0.75     75278\n",
      "       FAKE       0.74      0.78      0.76     75278\n",
      "\n",
      "avg / total       0.75      0.75      0.75    150556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with 'l1' penalty\n",
    "logistic = LogisticRegression(penalty='l1')\n",
    "logistic.fit(X_train, Y_train)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test, logistic.predict(X_val))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test, logistic.predict(X_val), \n",
    "                                    target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Accuracy =  0.756655330907\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL       0.79      0.70      0.74     75278\n",
      "       FAKE       0.73      0.81      0.77     75278\n",
      "\n",
      "avg / total       0.76      0.76      0.76    150556\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranava/miniconda2/envs/pytorch2/lib/python2.7/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Linear Support Vector Classifier with l2 regularizer and hinge loss\n",
    "linearsvc = LinearSVC(penalty='l2', loss='hinge', verbose=1)\n",
    "linearsvc.fit(X_train, Y_train)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test, linearsvc.predict(X_val))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test, linearsvc.predict(X_val), \n",
    "                                    target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.945076914902\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL       0.95      0.94      0.94     75278\n",
      "       FAKE       0.94      0.95      0.95     75278\n",
      "\n",
      "avg / total       0.95      0.95      0.95    150556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision tree classifier\n",
    "decisiontree = DecisionTreeClassifier(random_state=0)\n",
    "decisiontree.fit(X_train, Y_train)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test, decisiontree.predict(X_val))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test, decisiontree.predict(X_val), \n",
    "                                    target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.826476527007\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL       0.76      0.96      0.85     75278\n",
      "       FAKE       0.95      0.69      0.80     75278\n",
      "\n",
      "avg / total       0.85      0.83      0.82    150556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# standard Gradient Boosting Classifier \n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, Y_train)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test, gb.predict(X_val.toarray()))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test, gb.predict(X_val.toarray()), \n",
    "                                    target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.751275272988\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL       0.75      0.76      0.75     75278\n",
      "       FAKE       0.76      0.74      0.75     75278\n",
      "\n",
      "avg / total       0.75      0.75      0.75    150556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extremely randomized tree classifier.\n",
    "ert = ExtraTreeClassifier(splitter='best')\n",
    "ert.fit(X_train, Y_train)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test, ert.predict(X_val.toarray()))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test, ert.predict(X_val), \n",
    "                                    target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(decisiontree, open('decisiontreeclassifiermodel.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.948444432636\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL       0.96      0.94      0.95     75278\n",
      "       FAKE       0.94      0.96      0.95     75278\n",
      "\n",
      "avg / total       0.95      0.95      0.95    150556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier as in the FOIL paper\n",
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, random_state=1)\n",
    "mlp.fit(X_train, Y_train)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test, mlp.predict(X_val.toarray()))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test, mlp.predict(X_val), \n",
    "                                    target_names=target_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('REAL', 0.94007545365179734), ('FAKE', 0.95681341162092515)]\n"
     ]
    }
   ],
   "source": [
    "cmat = metrics.confusion_matrix(Y_test, mlp.predict(X_val.toarray()))\n",
    "print zip(target_names, cmat.diagonal()/cmat.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL     0.9568    0.9414    0.9490     75278\n",
      "       FAKE     0.9423    0.9575    0.9499     75278\n",
      "\n",
      "avg / total     0.9496    0.9495    0.9495    150556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print metrics.classification_report(Y_test, mlp.predict(X_val), \n",
    "                                    target_names=target_names, digits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
