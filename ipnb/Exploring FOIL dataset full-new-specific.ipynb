{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "import scipy.sparse as ss \n",
    "\n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC \n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training data:\n",
    "# train_feats = BOW linguistic features\n",
    "# train_image_feats = BOC image categorical features\n",
    "# train_y = FOILED or NOT FOILED => IF FOILED = 1, else 0\n",
    "train_feats_VERB = sio.mmread('data_new/train_feats_VERB.mtx')\n",
    "train_image_feats_VERB = sio.mmread('data_new/train_image_feats_VERB.mtx')\n",
    "train_target_VERB = np.array(sio.mmread('data_new/train_y_VERB.mtx').todense()).tolist()[0]\n",
    "#############\n",
    "# validation data: Same pattern as training; \n",
    "# The testing data comes from the karpathy 5k validation set only. \n",
    "val_feats_VERB = sio.mmread('data_new/test_feats_VERB.mtx')\n",
    "val_image_feats_VERB = sio.mmread('data_new/test_image_feats_VERB.mtx')\n",
    "val_target_VERB = np.array(sio.mmread('data_new/test_y_VERB.mtx').todense()).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training data:\n",
    "# train_feats = BOW linguistic features\n",
    "# train_image_feats = BOC image categorical features\n",
    "# train_y = FOILED or NOT FOILED => IF FOILED = 1, else 0\n",
    "train_feats_ADJ = sio.mmread('data_new/train_feats_ADJ.mtx')\n",
    "train_image_feats_ADJ = sio.mmread('data_new/train_image_feats_ADJ.mtx')\n",
    "train_target_ADJ = np.array(sio.mmread('data_new/train_y_ADJ.mtx').todense()).tolist()[0]\n",
    "#############\n",
    "# validation data: Same pattern as training; \n",
    "# The testing data comes from the karpathy 5k validation set only. \n",
    "val_feats_ADJ = sio.mmread('data_new/test_feats_ADJ.mtx')\n",
    "val_image_feats_ADJ = sio.mmread('data_new/test_image_feats_ADJ.mtx')\n",
    "val_target_ADJ = np.array(sio.mmread('data_new/test_y_ADJ.mtx').todense()).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training data:\n",
    "# train_feats = BOW linguistic features\n",
    "# train_image_feats = BOC image categorical features\n",
    "# train_y = FOILED or NOT FOILED => IF FOILED = 1, else 0\n",
    "train_feats_ADV = sio.mmread('data_new/train_feats_ADV.mtx')\n",
    "train_image_feats_ADV = sio.mmread('data_new/train_image_feats_ADV.mtx')\n",
    "train_target_ADV = np.array(sio.mmread('data_new/train_y_ADV.mtx').todense()).tolist()[0]\n",
    "#############\n",
    "# validation data: Same pattern as training; \n",
    "# The testing data comes from the karpathy 5k validation set only. \n",
    "val_feats_ADV = sio.mmread('data_new/test_feats_ADV.mtx')\n",
    "val_image_feats_ADV = sio.mmread('data_new/test_image_feats_ADV.mtx')\n",
    "val_target_ADV = np.array(sio.mmread('data_new/test_y_ADV.mtx').todense()).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training data:\n",
    "# train_feats = BOW linguistic features\n",
    "# train_image_feats = BOC image categorical features\n",
    "# train_y = FOILED or NOT FOILED => IF FOILED = 1, else 0\n",
    "train_feats_PP = sio.mmread('data_new/train_feats_PP.mtx')\n",
    "train_image_feats_PP = sio.mmread('data_new/train_image_feats_PP.mtx')\n",
    "train_target_PP = np.array(sio.mmread('data_new/train_y_PP.mtx').todense()).tolist()[0]\n",
    "#############\n",
    "# validation data: Same pattern as training; \n",
    "# The testing data comes from the karpathy 5k validation set only. \n",
    "val_feats_PP = sio.mmread('data_new/test_feats_PP.mtx')\n",
    "val_image_feats_PP = sio.mmread('data_new/test_image_feats_PP.mtx')\n",
    "val_target_PP = np.array(sio.mmread('data_new/test_y_PP.mtx').todense()).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data processing, concatinating images with\n",
    "# linguistic features and image features \n",
    "#X_train_VERB = ss.hstack([(train_feats_VERB), train_image_feats_VERB])\n",
    "#X_train = ss.hstack([binarize(train_feats), train_image_feats])\n",
    "X_train_VERB = train_feats_VERB\n",
    "\n",
    "#X_val_VERB = ss.hstack([(val_feats_VERB), val_image_feats_VERB])\n",
    "#X_val = ss.hstack([binarize(val_feats), val_image_feats])\n",
    "X_val_VERB = val_feats_VERB\n",
    "Y_train_VERB = np.array(train_target_VERB)\n",
    "Y_test_VERB = np.array(val_target_VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data processing, concatinating images with\n",
    "# linguistic features and image features \n",
    "X_train_ADJ = ss.hstack([(train_feats_ADJ), train_image_feats_ADJ])\n",
    "#X_train = ss.hstack([binarize(train_feats), train_image_feats])\n",
    "\n",
    "X_val_ADJ = ss.hstack([(val_feats_ADJ), val_image_feats_ADJ])\n",
    "#X_val = ss.hstack([binarize(val_feats), val_image_feats])\n",
    "\n",
    "Y_train_ADJ = np.array(train_target_ADJ)\n",
    "Y_test_ADJ = np.array(val_target_ADJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data processing, concatinating images with\n",
    "# linguistic features and image features \n",
    "X_train_ADV = ss.hstack([(train_feats_ADV), train_image_feats_ADV])\n",
    "#X_train = ss.hstack([binarize(train_feats), train_image_feats])\n",
    "\n",
    "X_val_ADV = ss.hstack([(val_feats_ADV), val_image_feats_ADV])\n",
    "#X_val = ss.hstack([binarize(val_feats), val_image_feats])\n",
    "\n",
    "Y_train_ADV = np.array(train_target_ADV)\n",
    "Y_test_ADV = np.array(val_target_ADV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data processing, concatinating images with\n",
    "# linguistic features and image features \n",
    "X_train_PP = ss.hstack([(train_feats_PP), train_image_feats_PP])\n",
    "#X_train = ss.hstack([binarize(train_feats), train_image_feats])\n",
    "\n",
    "X_val_PP = ss.hstack([(val_feats_PP), val_image_feats_PP])\n",
    "#X_val = ss.hstack([binarize(val_feats), val_image_feats])\n",
    "\n",
    "Y_train_PP = np.array(train_target_PP)\n",
    "Y_test_PP = np.array(val_target_PP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.751906267435\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL       0.77      0.73      0.75     75278\n",
      "       FAKE       0.74      0.78      0.76     75278\n",
      "\n",
      "avg / total       0.75      0.75      0.75    150556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with 'l1' penalty\n",
    "logistic = LogisticRegression(penalty='l1')\n",
    "logistic.fit(X_train, Y_train)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test, logistic.predict(X_val))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test, logistic.predict(X_val), \n",
    "                                    target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.973192790683\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL     0.9858    0.9869    0.9864     30263\n",
      "       FAKE     0.1043    0.0968    0.1004       475\n",
      "\n",
      "avg / total     0.9722    0.9732    0.9727     30738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_ADV = LogisticRegression(penalty='l1', class_weight='balanced')\n",
    "logreg_ADV.fit(X_train_ADV, Y_train_ADV)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test_ADV, logreg_ADV.predict(X_val_ADV.toarray()))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test_ADV, logreg_ADV.predict(X_val_ADV), \n",
    "                                    target_names=target_names, digits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Accuracy =  0.75741916629\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL       0.79      0.70      0.74     75278\n",
      "       FAKE       0.73      0.82      0.77     75278\n",
      "\n",
      "avg / total       0.76      0.76      0.76    150556\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Linear Support Vector Classifier with l2 regularizer and hinge loss\n",
    "linearsvc = LinearSVC(penalty='l2', loss='hinge', verbose=1)\n",
    "linearsvc.fit(X_train, Y_train)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test, linearsvc.predict(X_val))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test, linearsvc.predict(X_val), \n",
    "                                    target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.947257258448\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL       0.97      0.97      0.97     30263\n",
      "       FAKE       0.75      0.71      0.73      3353\n",
      "\n",
      "avg / total       0.95      0.95      0.95     33616\n",
      "\n",
      "[('REAL', 0.97389551597660506), ('FAKE', 0.70682970474202211)]\n"
     ]
    }
   ],
   "source": [
    "# Decision tree classifier\n",
    "decisiontree = DecisionTreeClassifier(random_state=0, class_weight='balanced')\n",
    "decisiontree.fit(X_train_VERB, Y_train_VERB)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test_VERB, decisiontree.predict(X_val_VERB))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test_VERB, decisiontree.predict(X_val_VERB), \n",
    "                                    target_names=target_names)\n",
    "cmat = metrics.confusion_matrix(Y_test_VERB, decisiontree.predict(X_val_VERB.toarray()))\n",
    "print zip(target_names, cmat.diagonal()/cmat.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.826456600866\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL       0.76      0.96      0.85     75278\n",
      "       FAKE       0.95      0.69      0.80     75278\n",
      "\n",
      "avg / total       0.85      0.83      0.82    150556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# standard Gradient Boosting Classifier \n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, Y_train)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test, gb.predict(X_val.toarray()))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test, gb.predict(X_val.toarray()), \n",
    "                                    target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.76075347379\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL       0.76      0.77      0.76     75278\n",
      "       FAKE       0.76      0.75      0.76     75278\n",
      "\n",
      "avg / total       0.76      0.76      0.76    150556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extremely randomized tree classifier.\n",
    "ert = ExtraTreeClassifier(splitter='best')\n",
    "ert.fit(X_train, Y_train)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test, ert.predict(X_val.toarray()))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test, ert.predict(X_val), \n",
    "                                    target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(decisiontree, open('decisiontreeclassifiermodel.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.949458591147\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL     0.9581    0.9870    0.9723     30263\n",
      "       FAKE     0.8387    0.6108    0.7068      3353\n",
      "\n",
      "avg / total     0.9462    0.9495    0.9459     33616\n",
      "\n",
      "[('REAL', 0.98698080163896507), ('FAKE', 0.61079630181926636)]\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier as in the FOIL paper\n",
    "mlp_VERB = MLPClassifier(solver='lbfgs', alpha=1e-5, random_state=1)\n",
    "mlp_VERB.fit(X_train_VERB, Y_train_VERB)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test_VERB, mlp_VERB.predict(X_val_VERB.toarray()))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test_VERB, mlp_VERB.predict(X_val_VERB), \n",
    "                                    target_names=target_names, digits=4)\n",
    "\n",
    "cmat = metrics.confusion_matrix(Y_test_VERB, mlp_VERB.predict(X_val_VERB.toarray()))\n",
    "print zip(target_names, cmat.diagonal()/cmat.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.898252021915\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL     0.8930    0.9751    0.9322     30263\n",
      "       FAKE     0.9172    0.7029    0.7959     11900\n",
      "\n",
      "avg / total     0.8998    0.8983    0.8938     42163\n",
      "\n",
      "[('REAL', 0.97505204374979348), ('FAKE', 0.70294117647058818)]\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier as in the FOIL paper\n",
    "mlp_ADJ = MLPClassifier(solver='lbfgs', alpha=1e-5, random_state=1)\n",
    "mlp_ADJ.fit(X_train_ADJ, Y_train_ADJ)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test_ADJ, mlp_ADJ.predict(X_val_ADJ.toarray()))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test_ADJ, mlp_ADJ.predict(X_val_ADJ), \n",
    "                                    target_names=target_names, digits=4)\n",
    "\n",
    "cmat = metrics.confusion_matrix(Y_test_ADJ, mlp_ADJ.predict(X_val_ADJ.toarray()))\n",
    "print zip(target_names, cmat.diagonal()/cmat.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.917581766003\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL       0.92      0.97      0.94     30263\n",
      "       FAKE       0.91      0.79      0.84     11900\n",
      "\n",
      "avg / total       0.92      0.92      0.92     42163\n",
      "\n",
      "[('REAL', 0.96963288504113931), ('FAKE', 0.78521008403361348)]\n"
     ]
    }
   ],
   "source": [
    "decisiontree = DecisionTreeClassifier(random_state=0, class_weight='balanced')\n",
    "decisiontree.fit(X_train_ADJ, Y_train_ADJ)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test_ADJ, decisiontree.predict(X_val_ADJ))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test_ADJ, decisiontree.predict(X_val_ADJ), \n",
    "                                    target_names=target_names)\n",
    "cmat = metrics.confusion_matrix(Y_test_ADJ, decisiontree.predict(X_val_ADJ.toarray()))\n",
    "print zip(target_names, cmat.diagonal()/cmat.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.981586310105\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL     0.9850    0.9965    0.9907     30263\n",
      "       FAKE     0.1301    0.0337    0.0535       475\n",
      "\n",
      "avg / total     0.9718    0.9816    0.9762     30738\n",
      "\n",
      "[('REAL', 0.99646432937910978), ('FAKE', 0.033684210526315789)]\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier as in the FOIL paper\n",
    "mlp_ADV = MLPClassifier(solver='lbfgs', alpha=1e-6, random_state=1, verbose=True)\n",
    "mlp_ADV.fit(X_train_ADV, Y_train_ADV)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test_ADV, mlp_ADV.predict(X_val_ADV.toarray()))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test_ADV, mlp_ADV.predict(X_val_ADV), \n",
    "                                    target_names=target_names, digits=4)\n",
    "cmat = metrics.confusion_matrix(Y_test_ADV, mlp_ADV.predict(X_val_ADV.toarray()))\n",
    "print zip(target_names, cmat.diagonal()/cmat.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.979569262802\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL       0.99      0.99      0.99     30263\n",
      "       FAKE       0.16      0.08      0.11       475\n",
      "\n",
      "avg / total       0.97      0.98      0.98     30738\n",
      "\n",
      "[('REAL', 0.99372170637412016), ('FAKE', 0.077894736842105267)]\n"
     ]
    }
   ],
   "source": [
    "decisiontree = DecisionTreeClassifier(random_state=23, class_weight='balanced')\n",
    "decisiontree.fit(X_train_ADV, Y_train_ADV)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test_ADV, decisiontree.predict(X_val_ADV))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test_ADV, decisiontree.predict(X_val_ADV), \n",
    "                                    target_names=target_names)\n",
    "cmat = metrics.confusion_matrix(Y_test_ADV, decisiontree.predict(X_val_ADV.toarray()))\n",
    "print zip(target_names, cmat.diagonal()/cmat.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.809183363032\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL     0.8107    0.9261    0.8646     30263\n",
      "       FAKE     0.8046    0.5846    0.6772     15755\n",
      "\n",
      "avg / total     0.8086    0.8092    0.8004     46018\n",
      "\n",
      "[('REAL', 0.92611439711859367), ('FAKE', 0.58457632497619805)]\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier as in the FOIL paper\n",
    "mlp_PP = MLPClassifier(solver='lbfgs', alpha=1e-5, random_state=1, verbose=True)\n",
    "mlp_PP.fit(X_train_PP, Y_train_PP)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test_PP, mlp_PP.predict(X_val_PP.toarray()))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test_PP, mlp_PP.predict(X_val_PP), \n",
    "                                    target_names=target_names, digits=4)\n",
    "\n",
    "cmat = metrics.confusion_matrix(Y_test_PP, mlp_PP.predict(X_val_PP.toarray()))\n",
    "print zip(target_names, cmat.diagonal()/cmat.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.787539658395\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       REAL       0.80      0.90      0.85     30263\n",
      "       FAKE       0.75      0.58      0.65     15755\n",
      "\n",
      "avg / total       0.78      0.79      0.78     46018\n",
      "\n",
      "[('REAL', 0.89806033770610982), ('FAKE', 0.57524595366550302)]\n"
     ]
    }
   ],
   "source": [
    "decisiontree = DecisionTreeClassifier(random_state=0, class_weight='balanced')\n",
    "decisiontree.fit(X_train_PP, Y_train_PP)\n",
    "print 'Accuracy = ', metrics.accuracy_score(Y_test_PP, decisiontree.predict(X_val_PP))\n",
    "target_names = ['REAL', 'FAKE']\n",
    "print metrics.classification_report(Y_test_PP, decisiontree.predict(X_val_PP), \n",
    "                                    target_names=target_names)\n",
    "cmat = metrics.confusion_matrix(Y_test_PP, decisiontree.predict(X_val_PP.toarray()))\n",
    "print zip(target_names, cmat.diagonal()/cmat.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spacy.en import English\n",
    "import spacy.en\n",
    "spacy.load('en')\n",
    "nlp = English()\n",
    "\n",
    "def print_fine_pos(token):\n",
    "    return (token.tag_)\n",
    "\n",
    "def pos_tags(sentence):\n",
    "#    sentence = unicode(sentence, \"utf-8\")\n",
    "    tokens = nlp(sentence)\n",
    "    tags = []\n",
    "    for tok in tokens:\n",
    "        tags.append((tok,print_fine_pos(tok)))\n",
    "    return tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multiSentence = \"There is an art, it says, or rather, a knack to flying.\" \\\n",
    "                 \"The knack lies in learning how to throw yourself at the ground and miss.\" \\\n",
    "                 \"In the beginning the Universe was created. This has made a lot of people \"\\\n",
    "                 \"very angry and been widely regarded as a bad move.\"\n",
    "\n",
    "parsed = nlp(unicode(multiSentence, 'utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'There', u'ADV')\n",
      "(u'is', u'VERB')\n",
      "(u'an', u'DET')\n",
      "(u'art', u'NOUN')\n",
      "(u',', u'PUNCT')\n",
      "(u'it', u'PRON')\n",
      "(u'says', u'VERB')\n",
      "(u',', u'PUNCT')\n",
      "(u'or', u'CCONJ')\n",
      "(u'rather', u'ADV')\n",
      "(u',', u'PUNCT')\n",
      "(u'a', u'DET')\n",
      "(u'knack', u'NOUN')\n",
      "(u'to', u'ADP')\n",
      "(u'flying', u'NOUN')\n",
      "(u'.', u'PUNCT')\n"
     ]
    }
   ],
   "source": [
    "for span in parsed.sents:\n",
    "    sent = [parsed[i] for i in range(span.start, span.end)]\n",
    "    break\n",
    "\n",
    "for token in sent:\n",
    "    print(token.orth_, token.pos_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[Ep:   0/ 50] TrL: 0.00001026, TeL: 0.00001951, TrAcc: 78.92110, TeAcc: 80.00780, True: 100.00000, Fake: \n",
    "0.02000\n",
    "[Ep:   1/ 50] TrL: 0.00001011, TeL: 0.00001950, TrAcc: 80.00957, TeAcc: 80.01365, True: 100.00000, Fake: \n",
    "0.22763\n",
    "[Ep:   2/ 50] TrL: 0.00001011, TeL: 0.00001950, TrAcc: 80.01144, TeAcc: 80.01561, True: 99.99875, Fake: 0\n",
    ".23763\n",
    "[Ep:   3/ 50] TrL: 0.00001006, TeL: 0.00001924, TrAcc: 80.01346, TeAcc: 80.01951, True: 99.99750, Fake: 0\n",
    ".25263\n",
    "[Ep:   4/ 50] TrL: 0.00000980, TeL: 0.00001847, TrAcc: 80.10067, TeAcc: 80.26724, True: 99.55862, Fake: 2\n",
    ".83577\n",
    "[Ep:   5/ 50] TrL: 0.00000940, TeL: 0.00001816, TrAcc: 80.45569, TeAcc: 80.58715, True: 98.56205, Fake: 8.41257\n",
    "[Ep:   6/ 50] TrL: 0.00000925, TeL: 0.00001806, TrAcc: 80.76453, TeAcc: 80.71199, True: 98.51389, Fake: 9.31045\n",
    "[Ep:   7/ 50] TrL: 0.00000920, TeL: 0.00001800, TrAcc: 80.91961, TeAcc: 80.61250, True: 97.19344, Fake: 13.18148\n",
    "[Ep:   8/ 50] TrL: 0.00000916, TeL: 0.00001795, TrAcc: 81.03934, TeAcc: 80.65737, True: 97.49489, Fake: 14.01700\n",
    "[Ep:   9/ 50] TrL: 0.00000913, TeL: 0.00001799, TrAcc: 81.11085, TeAcc: 80.49546, True: 97.12482, Fake: 14.69700\n",
    "[Ep:  10/ 50] TrL: 0.00000908, TeL: 0.00001798, TrAcc: 81.26975, TeAcc: 80.50132, True: 97.10292, Fake: 14.41437\n",
    "[Ep:  11/ 50] TrL: 0.00000907, TeL: 0.00001798, TrAcc: 81.29711, TeAcc: 80.46816, True: 96.97351, Fake: 15.03962\n",
    "[Ep:  12/ 50] TrL: 0.00000906, TeL: 0.00001801, TrAcc: 81.31523, TeAcc: 80.52277, True: 97.30923, Fake: 13.83674\n",
    "[Ep:  13/ 50] TrL: 0.00000905, TeL: 0.00001798, TrAcc: 81.33064, TeAcc: 80.53058, True: 97.31864, Fake: 14.01174\n",
    "[Ep:  14/ 50] TrL: 0.00000905, TeL: 0.00001797, TrAcc: 81.34172, TeAcc: 80.45255, True: 96.97476, Fake: 14.80200\n",
    "[Ep:  15/ 50] TrL: 0.00000905, TeL: 0.00001798, TrAcc: 81.36364, TeAcc: 80.53643, True: 97.24298, Fake: 14.13674\n",
    "[Ep:  16/ 50] TrL: 0.00000904, TeL: 0.00001799, TrAcc: 81.37465, TeAcc: 80.47596, True: 97.07417, Fake: 14.65700\n",
    "[Ep:  17/ 50] TrL: 0.00000904, TeL: 0.00001797, TrAcc: 81.39450, TeAcc: 80.46816, True: 96.97351, Fake: 15.03962\n",
    "[Ep:  18/ 50] TrL: 0.00000903, TeL: 0.00001799, TrAcc: 81.39923, TeAcc: 80.43695, True: 96.68213, Fake: 15.73988\n",
    "[Ep:  19/ 50] TrL: 0.00000903, TeL: 0.00001798, TrAcc: 81.41991, TeAcc: 80.47206, True: 97.09857, Fake: 14.74200\n",
    "[Ep:  20/ 50] TrL: 0.00000902, TeL: 0.00001799, TrAcc: 81.44363, TeAcc: 80.45060, True: 96.98667, Fake: 15.51988\n",
    "[Ep:  21/ 50] TrL: 0.00000902, TeL: 0.00001799, TrAcc: 81.44608, TeAcc: 80.45840, True: 97.01917, Fake: 15.21725\n",
    "[Ep:  22/ 50] TrL: 0.00000902, TeL: 0.00001799, TrAcc: 81.44832, TeAcc: 80.46425, True: 96.99417, Fake: 15.52488\n",
    "\n",
    "[Ep:  28/ 50] TrL: 0.00000902, TeL: 0.00001799, TrAcc: 81.45918, TeAcc: 80.46621, True: 96.94851, Fake: 1\n",
    "5.51988  \n",
    "[Ep:  29/ 50] TrL: 0.00000902, TeL: 0.00001799, TrAcc: 81.46128, TeAcc: 80.45450, True: 96.92726, Fake: 1\n",
    "5.57488  \n",
    "[Ep:  30/ 50] TrL: 0.00000901, TeL: 0.00001799, TrAcc: 81.46514, TeAcc: 80.46425, True: 96.98542, Fake: 15.55988  \n",
    "[Ep:  31/ 50] TrL: 0.00000901, TeL: 0.00001799, TrAcc: 81.46305, TeAcc: 80.46035, True: 96.98292, Fake: 15.55988  \n",
    "[Ep:  32/ 50] TrL: 0.00000901, TeL: 0.00001799, TrAcc: 81.46510, TeAcc: 80.46425, True: 96.98542, Fake: 15.55988  \n",
    "[Ep:  33/ 50] TrL: 0.00000901, TeL: 0.00001799, TrAcc: 81.46474, TeAcc: 80.46816, True: 96.98792, Fake: 15.55988  \n",
    "[Ep:  34/ 50] TrL: 0.00000901, TeL: 0.00001799, TrAcc: 81.46449, TeAcc: 80.46035, True: 96.93101, Fake: 15.57488  \n",
    "[Ep:  35/ 50] TrL: 0.00000901, TeL: 0.00001799, TrAcc: 81.46478, TeAcc: 80.46621, True: 96.98667, Fake: 15.55988  \n",
    "[Ep:  36/ 50] TrL: 0.00000901, TeL: 0.00001799, TrAcc: 81.46496, TeAcc: 80.46621, True: 96.98667, Fake: 15.55988  \n",
    "[Ep:  37/ 50] TrL: 0.00000901, TeL: 0.00001799, TrAcc: 81.46528, TeAcc: 80.46816, True: 96.98917, Fake: 15.55488  \n",
    "[Ep:  38/ 50] TrL: 0.00000901, TeL: 0.00001799, TrAcc: 81.46590, TeAcc: 80.47011, True: 96.99042, Fake: 15.55488  \n",
    "[Ep:  39/ 50] TrL: 0.00000901, TeL: 0.00001799, TrAcc: 81.46644, TeAcc: 80.46230, True: 96.98292, Fake: 15.56488  \n",
    "[Ep:  40/ 50] TrL: 0.00000901, TeL: 0.00001799, TrAcc: 81.46723, TeAcc: 80.46621, True: 96.98542, Fake: 15.56488  \n",
    "[Ep:  41/ 50] TrL: 0.00000901, TeL: 0.00001799, TrAcc: 81.46583, TeAcc: 80.46425, True: 96.98542, Fake: 15.55988  \n",
    "[Ep:  42/ 50] TrL: 0.00000901, TeL: 0.00001799, TrAcc: 81.46590, TeAcc: 80.46621, True: 96.98667, Fake: 15.55988  \n",
    "[Ep:  43/ 50] TrL: 0.00000901, TeL: 0.00001799, TrAcc: 81.46565, TeAcc: 80.46621, True: 96.98667, Fake: 15.55988  \n",
    "[Ep:  44/ 50] TrL: 0.00000901, TeL: 0.00001799, TrAcc: 81.46593, TeAcc: 80.46621, True: 96.98667, Fake: 15.55988  \n",
    "[Ep:  45/ 50] TrL: 0.00000901, TeL: 0.00001799, TrAcc: 81.46601, TeAcc: 80.46621, True: 96.98667, Fake: 15.55988  \n",
    "[Ep:  46/ 50] TrL: 0.00000901, TeL: 0.00001799, TrAcc: 81.46557, TeAcc: 80.46621, True: 96.98667, Fake: 15.55988  \n",
    "[Ep:  47/ 50] TrL: 0.00000901, TeL: 0.00001799, TrAcc: 81.46561, TeAcc: 80.46621, True: 96.98667, Fake: 15.55988\n",
    "[Ep:  48/ 50] TrL: 0.00000901, TeL: 0.00001799, TrAcc: 81.46575, TeAcc: 80.46621, True: 96.98667, Fake: 15.55988\n",
    "[Ep:  49/ 50] TrL: 0.00000901, TeL: 0.00001799, TrAcc: 81.46601, TeAcc: 80.46621, True: 96.98667, Fake: 15.55988\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
